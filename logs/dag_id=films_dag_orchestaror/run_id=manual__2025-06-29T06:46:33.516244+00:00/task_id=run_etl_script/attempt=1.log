[2025-06-29T06:46:34.255+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: films_dag_orchestaror.run_etl_script manual__2025-06-29T06:46:33.516244+00:00 [queued]>
[2025-06-29T06:46:34.263+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: films_dag_orchestaror.run_etl_script manual__2025-06-29T06:46:33.516244+00:00 [queued]>
[2025-06-29T06:46:34.264+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-06-29T06:46:34.275+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): run_etl_script> on 2025-06-29 06:46:33.516244+00:00
[2025-06-29T06:46:34.279+0000] {standard_task_runner.py:60} INFO - Started process 547 to run task
[2025-06-29T06:46:34.282+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'films_dag_orchestaror', 'run_etl_script', 'manual__2025-06-29T06:46:33.516244+00:00', '--job-id', '1624', '--raw', '--subdir', 'DAGS_FOLDER/orchestrator.py', '--cfg-path', '/tmp/tmpwt27qu0w']
[2025-06-29T06:46:34.285+0000] {standard_task_runner.py:88} INFO - Job 1624: Subtask run_etl_script
[2025-06-29T06:46:34.342+0000] {task_command.py:423} INFO - Running <TaskInstance: films_dag_orchestaror.run_etl_script manual__2025-06-29T06:46:33.516244+00:00 [running]> on host c3520c5c5ff0
[2025-06-29T06:46:34.431+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='films_dag_orchestaror' AIRFLOW_CTX_TASK_ID='run_etl_script' AIRFLOW_CTX_EXECUTION_DATE='2025-06-29T06:46:33.516244+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-06-29T06:46:33.516244+00:00'
[2025-06-29T06:51:08.140+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 199, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 216, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/orchestrator.py", line 17, in run_etl_script
    raise Exception(result.stderr)
Exception: psql:data_dump.sql:31: ERROR:  relation "actors" already exists
psql:data_dump.sql:34: FATAL:  terminating connection due to administrator command
psql:data_dump.sql:34: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.
psql:data_dump.sql:34: error: connection to server was lost
Traceback (most recent call last):
  File "/opt/airflow/etl/etl.py", line 74, in <module>
    subprocess.run(load_command,env=subprocess_env,check=True)
  File "/usr/local/lib/python3.10/subprocess.py", line 526, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['psql', '-h', 'destination_postgres', '-U', 'postgres', '-d', 'destination_db', '-a', '-f', 'data_dump.sql']' returned non-zero exit status 2.

[2025-06-29T06:51:08.164+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=films_dag_orchestaror, task_id=run_etl_script, execution_date=20250629T064633, start_date=20250629T064634, end_date=20250629T065108
[2025-06-29T06:51:08.204+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 1624 for task run_etl_script (psql:data_dump.sql:31: ERROR:  relation "actors" already exists
psql:data_dump.sql:34: FATAL:  terminating connection due to administrator command
psql:data_dump.sql:34: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.
psql:data_dump.sql:34: error: connection to server was lost
Traceback (most recent call last):
  File "/opt/airflow/etl/etl.py", line 74, in <module>
    subprocess.run(load_command,env=subprocess_env,check=True)
  File "/usr/local/lib/python3.10/subprocess.py", line 526, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['psql', '-h', 'destination_postgres', '-U', 'postgres', '-d', 'destination_db', '-a', '-f', 'data_dump.sql']' returned non-zero exit status 2.
; 547)
[2025-06-29T06:51:08.236+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-06-29T06:51:08.271+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
