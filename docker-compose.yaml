services :
  source_postgres : 
    container_name : source_database
    image : postgres:latest
    ports :
      - "5433:5432"
    networks:
      - etl_network
    environment:
      POSTGRES_DB: source_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: secret
    volumes: 
      - ./source_db_init/init.sql:/docker-entrypoint-initdb.d/init.sql
  destination_postgres : 
    image : postgres:latest
    container_name : destination_database
    ports :
      - "5434:5432"
    networks:
      - etl_network
    environment:
      POSTGRES_DB: destination_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: secret
    volumes :
      - postgres_data:/var/lib/postgresql/data 


  dbt :
    container_name: dbt_container
    image : ghcr.io/dbt-labs/dbt-postgres:1.9.latest
    volumes : 
      - ./dbt/my_dbt_project:/code
      - ./dbt:/root/.dbt
    working_dir : /code
    environment : 
      DBT_PROFILES_DIR: "/root/.dbt/"
    depends_on :
      - destination_postgres
    networks :
      - etl_network
    command : run

  etl_script :
    build:
      context: .
    command : ["python3","etl/etl.py"]
    networks :
      - etl_network
    depends_on:
      - source_postgres
      - destination_postgres

  postgres:
    container_name: airflow_postgres
    image : postgres:latest
    networks:
      - etl_network
    environment:
      POSTGRES_USER : postgres
      POSTGRES_DB : airflow_db
      POSTGRES_PASSWORD : secret
    volumes :
      - postgres_data_airflow:/var/lib/postgresql/data


  airflow-init:
    build: .  # Cambiado de "image: apache/airflow..." a "build: ."
    entrypoint: /bin/bash
    command: -c "airflow db init && airflow db migrate && airflow users create --username admin --firstname Admin --lastname airflow --role Admin --email haroldburbano2002@gmail.com --password secret"
    environment: 
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres:secret@postgres/airflow_db
      AIRFLOW__WEBSERVER__SECRET_KEY: secret
    depends_on:
      - postgres
    networks:
      - etl_network

  airflow_webserver:
    build: .  # Cambiado
    container_name: airflow_webs
    ports:
      - 8080:8080
    command: webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres:secret@postgres/airflow_db
      AIRFLOW__CORE__FERNET_KEY: bE5UVPgQz-ykieUXAPbDe5WAl6VKRBhYTO-cjL0CUfI=
      AIRFLOW__WEBSERVER__SECRET_KEY: secret
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./etl:/opt/airflow/etl/
      - ./logs:/opt/airflow/logs
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - airflow-init
      - source_postgres
      - destination_postgres
    networks:
      - etl_network

  airflow-scheduler:
    build: .  # Cambiado
    container_name: airflow_schedule
    entrypoint: /bin/bash
    command: -c "airflow scheduler"
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres:secret@postgres/airflow_db
      AIRFLOW__WEBSERVER__SECRET_KEY: secret
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./etl:/opt/airflow/etl/
      - ./logs:/opt/airflow/logs
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - airflow_webserver  
    networks: 
      - etl_network


volumes:
  postgres_data:
  postgres_data_airflow:

networks:
  etl_network:
    driver: bridge
